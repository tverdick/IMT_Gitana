{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from decimal import *\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from statistics import median\n",
    "\n",
    "from constants import bins_axis_names, bin_dimensions_regex, boat_speed_feature, \\\n",
    "                    boxplot_axis_name, feature_regex, identifier_features, \\\n",
    "                    fiber_optics_structure_features, fiber_optics_appendix_features, \\\n",
    "                    other_sensor_features, statistics_features, wind_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(fnames):\n",
    "    \"\"\"Read CSV file(s) to a Pandas Dataframe\"\"\"\n",
    "    def detect_and_read(fname):\n",
    "        with open(fname, 'rb') as f:\n",
    "            return pd.read_csv(fname, sep=';', encoding=chardet.detect(f.read())['encoding'])\n",
    "    df = pd.concat(map(lambda fname: detect_and_read(fname), fnames), sort=False)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df,\n",
    "                identifier_cols=identifier_features,\n",
    "                cols_to_preprocess=fiber_optics_structure_features + fiber_optics_appendix_features,\n",
    "                other_cols=other_sensor_features + wind_features + [boat_speed_feature],\n",
    "                regex=feature_regex):\n",
    "    preprocessed_df = pd.DataFrame()\n",
    "    cols = identifier_cols + cols_to_preprocess + other_cols\n",
    "    exclude = identifier_cols + other_cols\n",
    "    for old_col, new_col in cols: \n",
    "        if (old_col, new_col) in exclude: \n",
    "            preprocessed_df[new_col] = df[old_col] \n",
    "        else:\n",
    "            filter_regex = regex.format(old_col) \n",
    "            preprocessed_df[new_col] = df.filter(regex=(filter_regex)).mean(axis=1)\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol_speed(wind_speed, wind_angle):\n",
    "    \n",
    "    pol = pd.read_csv('Polaire.csv',sep=';', )\n",
    "    \n",
    "    wind_angle = abs(wind_angle)\n",
    "    \n",
    "    if wind_angle < 40:\n",
    "        wind_angle = 40\n",
    "    if wind_angle > 160 :\n",
    "        wind_angle = 160\n",
    "    \n",
    "    if wind_speed < 2:\n",
    "        wind_speed = 2\n",
    "    if wind_speed > 50:\n",
    "        wind_speed = 50\n",
    "    \n",
    "    for ws in pol:\n",
    "        if ws == \"TWA\":\n",
    "            1\n",
    "        else:\n",
    "            if int(ws) <= wind_speed:\n",
    "                ws_under = int(ws)\n",
    "            if int(ws) >= wind_speed:\n",
    "                ws_upper = int(ws)\n",
    "                break        \n",
    "    for wd in pol['TWA']:\n",
    "        if wd <= wind_angle:\n",
    "            wd_under = wd\n",
    "        if wd >= wind_angle:\n",
    "            wd_upper = wd\n",
    "            break\n",
    "                        \n",
    "    if wd_under == wd_upper and ws_under == ws_upper:\n",
    "        X = pol[pol['TWA'] == wind_angle][str(wind_speed)]\n",
    "    \n",
    "    if wd_under != wd_upper and ws_under != ws_upper:\n",
    "        \n",
    "        x1 = pol[pol['TWA'] == wd_under][str(ws_under)]\n",
    "        x2 = pol[pol['TWA'] == wd_under][str(ws_upper)]\n",
    "        x3 = pol[pol['TWA'] == wd_upper][str(ws_under)]\n",
    "        x4 = pol[pol['TWA'] == wd_upper][str(ws_upper)]\n",
    "        \n",
    "\n",
    "        a = (x2-x1)/(ws_upper-ws_under)\n",
    "        b = x1-a*ws_under\n",
    "        x5 = a*wind_speed + b\n",
    "\n",
    "        a_2 = (x4-x3)/(ws_upper-ws_under)\n",
    "        b_2 = x3-a_2*ws_under\n",
    "        x5_2 = a_2*wind_speed + b_2\n",
    "\n",
    "        A = (float(x5_2)-float(x5))/(wd_upper-wd_under)\n",
    "        B = x5-A*wd_under\n",
    "        X = A*wind_angle + B\n",
    "\n",
    "            \n",
    "    if wd_under == wd_upper and ws_under != ws_upper:\n",
    "        \n",
    "        x1 = pol[pol['TWA'] == wind_angle][str(ws_under)]\n",
    "        x2 = pol[pol['TWA'] == wind_angle][str(ws_upper)]\n",
    "        a = (x2-x1)/(ws_upper-ws_under)\n",
    "        b = x1-a*ws_under\n",
    "        X = a*wind_speed + b \n",
    "            \n",
    "    if wd_under != wd_upper and ws_under == ws_upper:\n",
    "        \n",
    "        x3 = pol[pol['TWA'] == wd_under][str(wind_speed)]\n",
    "        x4 = pol[pol['TWA'] == wd_upper][str(wind_speed)]  \n",
    "        a_2 = (float(x4)-float(x3))/(wd_upper-wd_under)\n",
    "        b_2 = x3-a_2*wd_under\n",
    "        X = a_2*wind_angle + b_2\n",
    "\n",
    "\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore RunTimeWarning.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ignore PyPlot warning.\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# Version number.\n",
    "version = 'v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prend en argument un csv et renvoie un dataframe avec uniquement les données utilisables pour analyser le comportement du bateau\n",
    "def clean_data():\n",
    "        \n",
    "    #Transformation du fichier csv en dataframe pandas\n",
    "    df = read_csv(map(lambda fname: '{}.csv'.format(fname), ['59', '111', '132', '308', '516', '525']))  \n",
    "    \n",
    "    #On renomme les colonnes\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    #On supprime les doublons\n",
    "    #df = df.drop_duplicates()\n",
    "    \n",
    "    ###############################Suppression des lignes inexploitables#############################################\n",
    "    \n",
    "    #Pour avoir le pourcentage de données supprimées\n",
    "    l1 = len(df)\n",
    "    \n",
    "    #On initialise la liste des lignes que l'on va supprimer\n",
    "    index_to_be_deleted = []\n",
    "    \n",
    "    #On y ajoute les données pour lesquelles la GV n'est pas montée et 5 minutes après\n",
    "    #no_Mainsail = df[df['Mainsail_Full'] == 0].index\n",
    "    #for i in no_Mainsail:\n",
    "    #    index_to_be_deleted.extend(np.arange(i, i+300))\n",
    "\n",
    "    #Indices pour lesquels le bateau est face au vent\n",
    "    #ind1 = df[(df[\"Wind_Angle\"] < 40) & (df[\"Wind_Angle\"] > -40)].index\n",
    "    \n",
    "    #Indices pour lesquels le bateau est en vent arrière\n",
    "    #ind2 = df[((df[\"Wind_Angle\"] < -170) & (df[\"Wind_Angle\"] > -181)) | ((df[\"Wind_Angle\"] > 170) & (df[\"Wind_Angle\"] < 181))].index\n",
    "    \n",
    "\n",
    "    \n",
    "    #On supprime les données 10 minutes avant et après les manoeuvres\n",
    "    #for i1 in ind1:\n",
    "    #    index_to_be_deleted.extend(np.arange(i1-600, i1+600))\n",
    "\n",
    "    #for i2 in ind2:\n",
    "    #    index_to_be_deleted.extend(np.arange(i2-600, i2+600))\n",
    "        \n",
    "    \n",
    "    #Indices pour lesquels le bateau avance à une vitesse inférieure à 75% de la polaire\n",
    "    ind3 = []\n",
    "    for i in df.index:\n",
    "        if math.isnan(df['Wind_Angle'][i]) == False and df['Boat_Speed'][i] < 0.75*float(pol_speed(float(df['Wind_Speed'][i]), float(df['Wind_Angle'][i]))):\n",
    "            ind3.append(i)\n",
    "            \n",
    "    index_to_be_deleted += ind3\n",
    "            \n",
    "    \n",
    "    #On supprime les indices qui apparaissent plusieurs fois\n",
    "    final_list = list(set(index_to_be_deleted))\n",
    "    \n",
    "\n",
    "    \n",
    "    #On supprime les lignes non pertinentes pour l'analyse du comportement du bateau\n",
    "    df = df.drop(final_list, errors = 'ignore')\n",
    "\n",
    "    \n",
    "    #On réinitialise les indices\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    #Pour avoir le pourcentage de données supprimées\n",
    "    l2 = len(final_list)\n",
    "    \n",
    "    #On print le pourcentage de données (lignes) supprimées\n",
    "    print(Decimal(l2/l1*100).quantize(Decimal('.1'), rounding=ROUND_HALF_UP),'% des données ont été ignorées')\n",
    "    \n",
    "    #####################################################################################################################\n",
    "    \n",
    "    ###############################Suppression des colonnes inexploitables#############################################\n",
    "\n",
    "    \n",
    "    del_columns = []\n",
    "\n",
    "    #On supprime les colonnes avec des Nan  (-de 50 données exploitables)\n",
    "    for i in df:\n",
    "        if df[i].count() < 50 :\n",
    "            del_columns.append(i)\n",
    "            df = df.drop(i, 1)\n",
    "    print('Variables avec trop de Nan :', del_columns)\n",
    "    \n",
    "    #On supprime les colonnes qui ne contiennent que des \"inf\" ou des \"-inf\" (-de 50 données exploitables)\n",
    "    col_inf = []\n",
    "    for i in df.iloc[:,2:]:\n",
    "        if str(df[i].mean()) == '-inf' or str(df[i].mean()) == 'inf' :\n",
    "            df = df.drop(i, 1)\n",
    "            col_inf.append(i)\n",
    "    print('Variables avec trop de \"inf\" ou \"-inf\" :', col_inf)\n",
    "    \n",
    "    #On supprime les colonnes qui ne contiennent que des 0 (-de 50 données exploitables)\n",
    "    col_with_0 = []\n",
    "    for i in df.iloc[:,2:]:\n",
    "        count = 0\n",
    "        for j in df[i]:\n",
    "            if j != 0.0:\n",
    "                count+=1\n",
    "        if count < 50:\n",
    "            df = df.drop(i, 1)\n",
    "            col_with_0.append(i)\n",
    "    print('Variables avec trop de 0 :', col_with_0)\n",
    "    \n",
    "    print(len(list(df)), \"variables sur\", len(list(df))+len(del_columns)+len(col_inf)+len(col_with_0), \"sont exploitables\")\n",
    "\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    \n",
    "    #On calcule et ajoute les variables qui n'ont de sens que sur un bord, et on supprime les deux utilisées\n",
    "    \n",
    "    #Création de variables\n",
    "\n",
    "    #Variables amures\n",
    "    #Tack\n",
    "    df['Tack'] = np.where(df['Apparent_Wind_Angle']<0,'Port','Starboard')\n",
    "    #Foil\n",
    "    df['Foil'] = np.where(df['Apparent_Wind_Angle']<0,df['Starboard_Foil_Max_Deformation_in_4'],df['Port_Foil_Max_Deformation_in_4'])\n",
    "    #Foil_rake\n",
    "    df['Foil_Rake'] = np.where(df['Apparent_Wind_Angle']<0,df['Starboard_Foil_Max_Deformation_in_4'],df['Port_Foil_Max_Deformation_in_4'])\n",
    "    #Rudder Angle\n",
    "    df['Rudder_Angle'] = np.where(df['Apparent_Wind_Angle']<0,df['Rudder_Angle_Starboard'],df['Rudder_Angle_Port'])\n",
    "    #Rudder_elevator\n",
    "    df['Rudder_Elevator'] = np.where(df['Apparent_Wind_Angle']<0,df['Rudder_Elevator_Angle_Starboard'],df['Rudder_Elevator_Angle_Port'])\n",
    "    #Rudder_Load_I\n",
    "    df['Rudder_Load_I'] = np.where(df['Apparent_Wind_Angle']<0,df['Rudder_Inside_Load_Starboard'],df['Rudder_Inside_Load_Port'])\n",
    "    #Rudder_Load_o\n",
    "    df['Rudder_Load_o'] = np.where(df['Apparent_Wind_Angle']<0,df['Rudder_Outside_Load_Starboard'],df['Rudder_Outside_Load_Port'])\n",
    "    #Shroud\n",
    "    df['Shroud'] = np.where(df['Apparent_Wind_Angle']<0,df['Shroud_Load_Starboard'],df['Shroud_Load_Port'])\n",
    "\n",
    "    #Variables portance\n",
    "    #Front_rake\n",
    "    df['Front_Rake'] = df['Foil_Rake'] + df['Board_Elevator_Angle_Center']\n",
    "    #Aft_rake\n",
    "    df['Aft_Rake'] = df['Rudder_Elevator'] + df['Rudder_Elevator_Angle_Center']\n",
    "    #Leeward_rake\n",
    "    df['Leeward_Rake'] = df['Foil_Rake'] + df['Rudder_Elevator']\n",
    "    #Center_rake\n",
    "    df['Center_rake'] = df['Rudder_Elevator_Angle_Center'] + df['Rudder_Elevator']\n",
    "    \n",
    "    #On supprime les colonnes qui ne sont plus utiles\n",
    "    \n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_1', 'Port_Foil_Max_Deformation_in_1' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_2', 'Port_Foil_Max_Deformation_in_2' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_3', 'Port_Foil_Max_Deformation_in_3' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_4', 'Port_Foil_Max_Deformation_in_4' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_5', 'Port_Foil_Max_Deformation_in_5' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_6', 'Port_Foil_Max_Deformation_in_6' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_7', 'Port_Foil_Max_Deformation_in_7' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_in_8', 'Port_Foil_Max_Deformation_in_8' ], errors = 'ignore')\n",
    "    \n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_1', 'Port_Foil_Min_Deformation_in_1' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_2', 'Port_Foil_Min_Deformation_in_2' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_3', 'Port_Foil_Min_Deformation_in_3' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_4', 'Port_Foil_Min_Deformation_in_4' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_5', 'Port_Foil_Min_Deformation_in_5' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_6', 'Port_Foil_Min_Deformation_in_6' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_7', 'Port_Foil_Min_Deformation_in_7' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_in_8', 'Port_Foil_Min_Deformation_in_8' ], errors = 'ignore')\n",
    "    \n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_1', 'Port_Foil_Max_Deformation_out_1' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_2', 'Port_Foil_Max_Deformation_out_2' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_3', 'Port_Foil_Max_Deformation_out_3' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_4', 'Port_Foil_Max_Deformation_out_4' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_5', 'Port_Foil_Max_Deformation_out_5' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_6', 'Port_Foil_Max_Deformation_out_6' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_7', 'Port_Foil_Max_Deformation_out_7' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Max_Deformation_out_8', 'Port_Foil_Max_Deformation_out_8' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_1', 'Port_Foil_Min_Deformation_out_1' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_2', 'Port_Foil_Min_Deformation_out_2' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_3', 'Port_Foil_Min_Deformation_out_3' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_4', 'Port_Foil_Min_Deformation_out_4' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_5', 'Port_Foil_Min_Deformation_out_5' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_6', 'Port_Foil_Min_Deformation_out_6' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_7', 'Port_Foil_Min_Deformation_out_7' ], errors = 'ignore')\n",
    "    df = df.drop(columns=['Starboard_Foil_Min_Deformation_out_8', 'Port_Foil_Min_Deformation_out_8' ], errors = 'ignore')\n",
    "    \n",
    "    df = df.drop(columns=['Rudder_Angle_Starboard', 'Rudder_Angle_Port' ])\n",
    "    df = df.drop(columns=['Rudder_Elevator_Angle_Starboard', 'Rudder_Elevator_Angle_Port' ])\n",
    "    df = df.drop(columns=['Rudder_Inside_Load_Starboard', 'Rudder_Inside_Load_Port' ])\n",
    "    df = df.drop(columns=['Rudder_Outside_Load_Starboard', 'Rudder_Outside_Load_Port' ])\n",
    "    df = df.drop(columns=['Shroud_Load_Starboard', 'Shroud_Load_Port' ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Final_Data.csv', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
